{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "correction = 0.2\n",
    "\n",
    "for line in lines:\n",
    "    for i in range(3):\n",
    "        source_path = line[i]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        #print(filename)\n",
    "        current_path = 'data/IMG/' + filename\n",
    "        #print(current_path)\n",
    "        #image = cv2.imread(current_path)\n",
    "        image = cv2.imread(current_path)[:,:,::-1]  # Read image and convert from BGR to RGB\n",
    "        images.append(image)\n",
    "\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "    measurements.append(measurement + correction)\n",
    "    measurements.append(measurement - correction)\n",
    "    #print (measurements)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Data loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images augumented\n"
     ]
    }
   ],
   "source": [
    "augumented_images, augumented_measurements = [], []\n",
    "\n",
    "for image, measuerement in zip(images, measurements):\n",
    "    augumented_images.append(image)\n",
    "    augumented_measurements.append(measuerement)\n",
    "    augumented_images.append(cv2.flip(image,1))\n",
    "    augumented_measurements.append(measuerement*-1.0)\n",
    "\n",
    "\n",
    "X_train = np.array(augumented_images)\n",
    "y_train = np.array(augumented_measurements)\n",
    "\n",
    "print(\"Images augumented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55617 samples, validate on 13905 samples\n",
      "Epoch 1/3\n",
      "55617/55617 [==============================] - 819s - loss: 0.0383 - val_loss: 0.1702\n",
      "Epoch 2/3\n",
      "32000/55617 [================>.............] - ETA: 256s - loss: 0.0336"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70, 25), (1, 1))))\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=3, verbose=1)\n",
    "\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Output visualization\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model MSE loss')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training set', 'Validation set'], loc='upper right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
